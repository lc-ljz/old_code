var tf=tf||{},long=long||{Long:require("long")},protobuf=protobuf||require("./protobuf");tf.ModelFactory=class{match(t){const e=t.identifier,s=e.split(".").pop().toLowerCase();if(s==="meta"&&t.tags("pb").size!==0)return!0;if(s==="pbtxt"||s==="prototxt"){if(e.endsWith("predict_net.pbtxt")||e.endsWith("predict_net.prototxt")||e.endsWith("init_net.pbtxt")||e.endsWith("init_net.prototxt"))return!1;const o=t.tags("pbtxt");if(o.has("input_stream")||o.has("output_stream"))return!1;if(o.has("node")||o.has("saved_model_schema_version")||o.has("meta_graphs")||o.has("graph_def"))return!0}if(s==="pb"||s==="pbtxt"||s==="prototxt"){if(e.endsWith("predict_net.pb")||e.endsWith("init_net.pb"))return!1;if(e=="tfhub_module.pb"){const r=t.buffer;if(r&&r.length==2&&r[0]==8&&r[1]==3)return!1}const o=t.tags("pb");if(o.size===0){const r=t.tags("pbtxt");if(r.has("input_stream")||r.has("output_stream"))return!1;if(r.has("node")||r.has("saved_model_schema_version")||r.has("meta_graphs")||r.has("graph_def"))return!0}else{if(o.has(1)&&o.get(1)===0&&o.has(2)&&o.get(2)===0&&o.has(9)&&o.get(9)===2)return!1;if(!Array.from(o.values()).some(r=>r===5))return!0}}if(s==="json")try{const o=JSON.parse(t.text);if(o&&o.format&&o.format==="graph-model"&&o.modelTopology)return!0}catch(o){}if((s==="index"||s==="ckpt")&&t.buffer.length>8){const o=t.buffer.subarray(t.buffer.length-8,t.buffer.length),r=[87,251,128,139,36,117,71,219];if(o.every((p,c)=>p===r[c]))return!0}return!1}open(t,e){return e.require("./tf-proto").then(()=>{tf.proto=protobuf.get("tf").tensorflow;let s=null,o=null,r=null;const p=t.identifier,c=p.split(".").pop().toLowerCase();switch(c){case"ckpt":case"index":return tf.ModelFactory._openBundle(t,e);case"json":try{const i=JSON.parse(t.text),a=new tf.proto.GraphDef,n=new tf.proto.MetaGraphDef;n.graph_def=a,s=new tf.proto.SavedModel,s.meta_graphs.push(n);for(const l of i.modelTopology.node)a.node.push(l),l.input=l.input||[];o="TensorFlow.js "+i.format,r=i.convertedBy||i.generatedBy||""}catch(i){throw new tf.Error("File text format is not TensorFlow.js graph-model ("+i.message+") in '"+p+"'.")}break;default:{const i=t.tags("pbtxt");if(i.has("node")||i.has("saved_model_schema_version")||i.has("meta_graphs")||i.has("graph_def")){if(i.has("saved_model_schema_version")||i.has("meta_graphs"))try{(p.endsWith("saved_model.pbtxt")||p.endsWith("saved_model.prototxt"))&&(s=tf.proto.SavedModel.decodeText(protobuf.TextReader.create(t.text)),o="TensorFlow Saved Model",s&&Object.prototype.hasOwnProperty.call(s,"saved_model_schema_version")&&(o=o+" v"+s.saved_model_schema_version.toString()))}catch(a){throw new tf.Error("File text format is not tensorflow.SavedModel ("+a.message+") in '"+p+"'.")}else if(i.has("graph_def"))try{if(!s){const a=tf.proto.MetaGraphDef.decodeText(protobuf.TextReader.create(t.text));s=new tf.proto.SavedModel,s.meta_graphs.push(a),o="TensorFlow MetaGraph"}}catch(a){throw new tf.Error("File text format is not tensorflow.MetaGraphDef ("+a.message+") in '"+p+"'.")}else if(i.has("node"))try{const a=tf.proto.GraphDef.decodeText(protobuf.TextReader.create(t.text)),n=new tf.proto.MetaGraphDef;n.graph_def=a,s=new tf.proto.SavedModel,s.meta_graphs.push(n),o="TensorFlow Graph"}catch(a){throw new tf.Error("File text format is not tensorflow.GraphDef ("+a.message+") in '"+p+"'.")}}else{try{if(p.endsWith("saved_model.pb")){const a=protobuf.Reader.create(t.buffer);s=tf.proto.SavedModel.decode(a),o="TensorFlow Saved Model",s&&Object.prototype.hasOwnProperty.call(s,"saved_model_schema_version")&&(o=o+" v"+s.saved_model_schema_version.toString())}}catch(a){const n=t.buffer;if(n.length>3&&n[0]==8&&n[1]==1&&n[2]==18)throw new tf.Error("File format is not tensorflow.SavedModel ("+a.message+") in '"+p+"'.")}try{if(!s&&c=="meta"){const a=protobuf.Reader.create(t.buffer),n=tf.proto.MetaGraphDef.decode(a);s=new tf.proto.SavedModel,s.meta_graphs.push(n),o="TensorFlow MetaGraph"}}catch(a){throw new tf.Error("File format is not tensorflow.MetaGraphDef ("+a.message+") in '"+p+"'.")}try{if(!s){const a=protobuf.Reader.create(t.buffer),n=tf.proto.GraphDef.decode(a),l=new tf.proto.MetaGraphDef;l.graph_def=n,s=new tf.proto.SavedModel,s.meta_graphs.push(l),o="TensorFlow Graph"}}catch(a){throw new tf.Error("File format is not tensorflow.GraphDef ("+a.message+") in '"+p+"'.")}}s&&s.meta_graphs&&s.meta_graphs.length>0&&s.meta_graphs[0].meta_info_def&&Object.prototype.hasOwnProperty.call(s.meta_graphs[0].meta_info_def,"tensorflow_version")&&(r="TensorFlow v"+s.meta_graphs[0].meta_info_def.tensorflow_version);break}}return tf.Metadata.open(e).then(i=>{if(s.meta_graphs.length===1&&s.meta_graphs[0].object_graph_def&&s.meta_graphs[0].object_graph_def.nodes&&s.meta_graphs[0].object_graph_def.nodes.length>0){const a="variables/variables.index";return t.request(a,null).then(n=>tf.TensorBundle.open(n,a,t,e).then(l=>tf.ModelFactory._openModel(a,e,i,s,o,r,l))).catch(()=>tf.ModelFactory._openModel(a,e,i,s,o,r,null))}return tf.ModelFactory._openModel(p,e,i,s,o,r,null)})})}static _openModel(t,e,s,o,r,p,c){try{return new tf.Model(s,o,r,p,c)}catch(i){e.exception(i,!1);const a=i&&i.message?i.message:i.toString();throw new tf.Error(a.replace(/\.$/,"")+" in '"+t+"'.")}}static _openBundle(t,e){return tf.Metadata.open(e).then(s=>{const o=t.identifier;return tf.TensorBundle.open(t.buffer,o,t,e).then(r=>new tf.Model(s,null,"TensorFlow Tensor Bundle v"+r.format.toString(),null,r)).catch(r=>{e.exception(r,!1);const p=r&&r.message?r.message:r.toString();throw new tf.Error(p.replace(/\.$/,"")+" in '"+o+"'.")})})}},tf.Model=class{constructor(t,e,s,o,r){if(this._format=s,this._producer=o||"",this._graphs=[],e){for(let i=0;i<e.meta_graphs.length;i++){const a=e.meta_graphs[i];let n=null;n=a.any_info?a.any_info.toString():e.meta_graphs.length>1?i.toString():"-",this._graphs.push(new tf.Graph(t,a,n,r))}const p=[],c=[...this._graphs];for(;c.length>0;){const i=c.shift();p.push(i);for(const a of i.functions)c.push(a)}this._graphs=p}else this._graphs.push(new tf.Graph(t,null,"",r))}get format(){return this._format}get producer(){return this._producer}get description(){return null}get graphs(){return this._graphs}},tf.Graph=class{constructor(t,e,s,o){if(this._metadata=t,this._version=null,this._name=s,this._inputs=[],this._outputs=[],this._nodes=[],this._functions=[],e&&e.graph_def){this._metadata=new tf.GraphMetadata(t,e.meta_info_def);const r=e.graph_def;r.versions?this._version="v"+r.versions.producer.toString():r.version?this._version=r.version:e.meta_info_def&&e.meta_info_def.tensorflow_version&&(this._version=e.meta_info_def.tensorflow_version),e.meta_info_def&&e.meta_info_def.tags&&(this._tags=e.meta_info_def.tags.join(", "));const p=r.node;if(p){const c={};this._namespaces={};for(const n of p){const l=n.name;if(c[l]=n,n.op!="Const"){const h=l.lastIndexOf("/");if(h!=-1){const u=l.substring(0,h);this._namespaces[u]=!0}}n.output=[]}for(const n of p){const l=n.input;n.input=[],n.controlDependencies=[];for(const h of l){const u=h.split(":",2),_=u[0],f=u.length==1?0:parseInt(u[1]);let d=_.startsWith("^")?_.substring(1):_;const y=c[d];if(d=f==0?d:d+":"+f.toString(),_.startsWith("^")?n.controlDependencies.push(d):n.input.push(d),y){for(let g=y.output.length;g<=f;g++)y.output.push("");y.output[f]=d}}}this._nodeOutputCountMap={};for(const n of p){for(const l of n.input)this._nodeOutputCountMap[l]=(this._nodeOutputCountMap[l]||0)+1;for(const l of n.controlDependencies)this._nodeOutputCountMap[l]=(this._nodeOutputCountMap[l]||0)+1}const i={};for(const n of p)if(n.op=="Const"&&n.input.length==0&&n.controlDependencies.length==0&&this._checkSingleOutput(n)){const l=n.attr.value;if(l&&Object.prototype.hasOwnProperty.call(l,"tensor")){const h=n.output[0];h&&(i[h]=new tf.Tensor(l.tensor,n.name,"Constant"))}}for(const n of p)if(n.op=="Identity"&&n.input.length==1&&n.controlDependencies.length==0&&this._checkSingleOutput(n)){const l=n.input[0],h=i[l];h&&(i[l]="-",h.kind="Identity Constant",i[n.output[0]]=h)}const a={};for(const n of p)if(n.op=="Placeholder"&&n.input.length==0&&n.controlDependencies.length==0&&n.output.length==1){const l=n.attr.dtype,h=n.attr.shape;if(l&&l.type&&h&&h.shape){const u=new tf.TensorType(l.type,h.shape),_=new tf.Argument(n.output[0],u,null);a[n.output[0]]=new tf.Parameter(n.name,[_])}}this._inputs=Object.keys(a).map(n=>a[n]);for(const n of p){const l=n.name;i[l]||a[l]||this._nodes.push(new tf.Node(this,n,n.op,n.name,i,null))}}if(r.library){const c=r.library.function;for(const i of c)this._functions.push(new tf.Function(this,i,this._metadata))}}else if(o){const r=[],p=new Map;for(const c of o.tensors){const i=c.name.split("/");if(o.format===2){if(c.name==="_CHECKPOINTABLE_OBJECT_GRAPH"||c.name.startsWith("optimizer/")||c.name.startsWith("keras_api/metrics/")||c.name.endsWith("/ExponentialMovingAverage")||c.name.indexOf(".OPTIMIZER_SLOT")!==-1)continue;c.name.endsWith("/.ATTRIBUTES/VARIABLE_VALUE")&&(i.pop(),i.pop())}const a=i.pop(),n=i.join("/");p.has(n)||(r.push(n),p.set(n,[])),p.get(n).push({name:a,value:c})}for(const c of r)this._nodes.push(new tf.Node(this,null,"Node",c,null,p.get(c)))}}get name(){return this._name}get version(){return this._version}get tags(){return this._tags}get groups(){return!1}get inputs(){return this._inputs}get outputs(){return this._outputs}get nodes(){return this._nodes}get metadata(){return this._metadata}get namespaces(){return this._namespaces}get functions(){return this._functions}_checkSingleOutput(t){if(t.output.length!=1)return!1;const e=t.output[0];return this._nodeOutputCountMap[e]==1}},tf.Parameter=class{constructor(t,e){this._name=t,this._arguments=e}get name(){return this._name}get visible(){return!0}get arguments(){return this._arguments}},tf.Argument=class{constructor(t,e,s){if(typeof t!="string")throw new tf.Error("Invalid argument identifier '"+JSON.stringify(t)+"'.");this._name=t,this._type=e||null,this._initializer=s||null}get name(){return this._name}get type(){return this._initializer?this._initializer.type:this._type}get initializer(){return this._initializer}},tf.Function=class{constructor(t,e,s){this._name=e.signature.name,this._version=null,this._tags=null,this._inputs=[],this._outputs=[],this._nodes=[],this._metadata=s,this._namespaces={},this._functions=[];const o=e.signature.input_arg;if(o)for(const a of o){const n=new tf.Argument(a.name,new tf.TensorType(a.type,null),null);this._inputs.push(new tf.Parameter(a.name,[n]))}const r={};for(const a of Object.keys(e.ret)){const n=e.ret[a].split(":",2);r[a]=n[0]}const p={},c=e.signature.output_arg;if(c)for(const a of c){const n=r[a.name];this._outputs.push(new tf.Parameter(a.name,[new tf.Argument(n,new tf.TensorType(a.type,null),null)])),p[n]=a.name}const i=e.node_def;if(i){const a={};for(const h of i){const u=h.name;if(a[u]=h,h.op!="Const"){const _=u.lastIndexOf("/");if(_!=-1){const f=u.substring(0,_);this._namespaces[f]=!0}}h.output=[]}for(const h of i){const u=h.input;h.input=[],h.controlDependencies=[];for(const _ of u){const f=_.split(":",3),d=f[0],y=f.length==1?0:parseInt(f[f.length-1]);let g=d.startsWith("^")?d.substring(1):d;const w=a[g];if(g=y==0?g:g+":"+y.toString(),d.startsWith("^")?h.controlDependencies.push(g):h.input.push(g),w){for(let m=w.output.length;m<=y;m++)w.output.push("");w.output[y]=g}}p[h.name]&&h.output.push(h.name)}const n={};for(const h of i){for(const u of h.input)n[u]=(n[u]||0)+1;for(const u of h.controlDependencies)n[u]=(n[u]||0)+1}const l={};for(const h of i)if(h.op=="Const"&&h.input.length==0&&h.controlDependencies.length==0&&tf.Function._checkSingleOutput(h,n)){const u=h.attr.value;if(u&&Object.prototype.hasOwnProperty.call(u,"tensor")){const _=h.output[0];_&&(l[_]=new tf.Tensor(u.tensor,h.name,"Constant"))}}for(const h of i)if(h.op=="Identity"&&h.input.length==1&&h.controlDependencies.length==0&&tf.Function._checkSingleOutput(h,n)){const u=h.input[0],_=l[u];_&&(l[u]="-",_.kind="Identity Constant",l[h.output[0]]=_)}for(const h of i)l[h.name]||this._nodes.push(new tf.Node(this,h,h.op,h.name,l,null))}}get name(){return this._name}get version(){return this._version}get tags(){return this._tags}get groups(){return!1}get inputs(){return this._inputs}get outputs(){return this._outputs}get nodes(){return this._nodes}get metadata(){return this._metadata}get namespaces(){return this._namespaces}get functions(){return this._functions}static _checkSingleOutput(t,e){return t.output.length==1&&e[t.output[0]]==1}},tf.Node=class{constructor(t,e,s,o,r,p){if(this._graph=t,this._type=s,this._name=o,this._attributes=[],this._inputs=[],this._outputs=[],e){Object.prototype.hasOwnProperty.call(e,"device")&&(this._device=e.device);const c=t.metadata;if(e.attr)for(const u of Object.keys(e.attr)){const _=c.attribute(this._type,u),f=!c.getAttributeVisibleMap(this._type)[u];this._attributes.push(new tf.Attribute(_,u,e.attr[u],f))}const i=c.type(this._type);let a=0;const n=e.input.filter(u=>!u.startsWith("^"));if(i&&i.inputs)for(const u of i.inputs){let _=1;if(u.numberAttr){const d=e.attr[u.numberAttr];d&&d.i&&(_=d.i)}else if(u.typeListAttr){const d=e.attr[u.typeListAttr];d&&d.list&&d.list.type&&(_=d.list.type.length)}const f=n.slice(a,a+_).map(d=>new tf.Argument(d,null,r[d]));this._inputs.push(new tf.Parameter(u.name,f)),a+=_}this._inputs=this._inputs.concat(n.slice(a).map((u,_)=>new tf.Parameter((a+_).toString(),[new tf.Argument(u,null,r[u])])));let l=0;const h=e.output;if(i&&i.outputs)for(const u of i.outputs){let _=1;if(u.numberAttr){const d=e.attr[u.numberAttr];d&&d.i&&(_=d.i)}else if(u.typeListAttr){const d=e.attr[u.typeListAttr];d&&d.list&&d.list.type&&(_=d.list.type.length)}const f=h.slice(l,l+_).map(d=>new tf.Argument(d,null,null));this._outputs.push(new tf.Parameter(u.name,f)),l+=_}this._outputs=this._outputs.concat(h.slice(l).map((u,_)=>new tf.Parameter((l+_).toString(),[new tf.Argument(u,null,null)]))),this._controlDependencies=e.controlDependencies}else if(p)for(const c of p)this._inputs.push(new tf.Parameter(c.name,[new tf.Argument(c.value.name,null,c.value)]))}get type(){return this._type}get name(){return this._name}get device(){return this._device||null}get group(){const t=this._name;if(this._graph.namespaces[t])return t;const e=t.lastIndexOf("/");if(e!=-1){const s=t.substring(0,e);if(this._graph.namespaces[s])return s}return""}get description(){return""}get domain(){return null}get metadata(){return this._graph.metadata.type(this.type)}get inputs(){return this._inputs}get outputs(){return this._outputs}get controlDependencies(){return this._controlDependencies}get attributes(){return this._attributes}},tf.Attribute=class{constructor(t,e,s,o){switch(this._name=e,this._value=null,this._type=null,Object.prototype.hasOwnProperty.call(s,"tensor")?(this._type="tensor",this._value=new tf.Tensor(s.tensor)):t&&t.type&&(this._type=t.type),s.value){case"type":this._type="type",this._value=tf.Tensor.formatDataType(s.type);break;case"i":this._value=s.i;break;case"f":this._value=s.f;break;case"b":this._value=s.b;break;case"shape":this._type="shape",this._value=new tf.TensorShape(s.shape);break;case"s":this._value=tf.Utility.decodeText(s.s);break;case"func":{const r=s.func;this._type="function",this._value=r.name;break}case"list":{const r=s.list;r.s&&r.s.length>0?this._value=r.s.map(p=>tf.Utility.decodeText(p)):r.i&&r.i.length>0?this._value=r.i:r.f&&r.f.length>0?this._value=r.f:r.type&&r.type.length>0?(this._type="type[]",this._value=r.type.map(p=>tf.Tensor.formatDataType(p))):r.shape&&r.shape.length>0?(this._type="shape[]",this._value=r.shape.map(p=>new tf.TensorShape(p))):this._value=[];break}}if(t){if(Object.prototype.hasOwnProperty.call(t,"visible")&&!t.visible)this._visible=!1;else if(Object.prototype.hasOwnProperty.call(t,"default")&&(!Array.isArray(this._value)||Array.isArray(t.default)||this._value.length===t.default.length)){let r=this._value,p=t.default;if(this._type==="float32"){const a=new Float32Array(1);a[0]=r,r=a[0],a[0]=p,p=a[0]}const c=tf.GraphMetadata._formatAttributeValue(r),i=tf.GraphMetadata._formatAttributeValue(p);JSON.stringify(c)==JSON.stringify(i)&&(this._visible=!1)}}e=="_output_shapes"&&(this._visible=!1,this._type="shape[]"),e=="_class"&&(this._visible=!1),o===!1&&(this._visible=!1)}get name(){return this._name}get type(){return this._type}get value(){return this._value}get visible(){return this._visible!=0}},tf.Tensor=class{constructor(t,e,s){this._type=new tf.TensorType(t.dtype,t.tensor_shape||t.tensorShape),this._name=e,this._kind=s||null,this._tensor=t}get name(){return this._name}get type(){return this._type}get kind(){return this._kind}set kind(t){this._kind=t}get state(){return this._context().state}get value(){const t=this._context();return t.state?null:(t.limit=Number.MAX_SAFE_INTEGER,this._decode(t,0))}toString(){const t=this._context();if(t.state)return"";t.limit=1e4;const e=this._decode(t,0);return JSON.stringify(e,null,4)}_context(){const t={state:null,index:0,count:0,size:1};if(!this._tensor.dtype)return t.state="Tensor has no data type.",t;const e=this._tensor.tensor_shape||this._tensor.tensorShape;if(!e||!e.dim)return t.state="Tensor has no dimensions.",t;for(const s of e.dim)t.size=t.size*(s.size?s.size:0);switch(this._tensor.dtype){case"DT_FLOAT":case tf.proto.DataType.DT_FLOAT:this._tensor.tensor_content&&this._tensor.tensor_content.length>0?t.rawData=new DataView(this._tensor.tensor_content.buffer,this._tensor.tensor_content.byteOffset,this._tensor.tensor_content.byteLength):this._tensor.float_val&&this._tensor.float_val.length==t.size?t.data=this._tensor.float_val:t.state="Tensor data is empty.";break;case tf.proto.DataType.DT_QINT8:case tf.proto.DataType.DT_QUINT8:this._tensor.tensor_content&&this._tensor.tensor_content.length>0?t.rawData=new DataView(this._tensor.tensor_content.buffer,this._tensor.tensor_content.byteOffset,this._tensor.tensor_content.byteLength):t.state="Tensor data is empty.";break;case tf.proto.DataType.DT_INT32:case tf.proto.DataType.DT_UINT32:this._tensor.tensor_content&&this._tensor.tensor_content.length>0?t.rawData=new DataView(this._tensor.tensor_content.buffer,this._tensor.tensor_content.byteOffset,this._tensor.tensor_content.byteLength):this._tensor.int_val&&this._tensor.int_val.length==t.size?t.data=this._tensor.int_val:t.state="Tensor data is empty.";break;case tf.proto.DataType.DT_STRING:this._tensor.tensor_content&&this._tensor.tensor_content.length>0?t.state="Tensor data type is not implemented.":this._tensor.string_val&&this._tensor.string_val.length==t.size?t.data=this._tensor.string_val:t.state="Tensor data is empty.";break;case tf.proto.DataType.DT_BOOL:t.state="Tensor data type 'bool' is not implemented.";break;default:t.state="Tensor data type '"+this._tensor.dtype+"' is not implemented."}return t.shape=e.dim.map(s=>s.size),t}_decode(t,e){let s=t.shape;s.length==0&&(s=[1]);const o=[],r=s[e];if(e==s.length-1)for(let p=0;p<r;p++){if(t.count>t.limit)return o.push("..."),o;if(t.data){const c=t.data[t.index++];o.push(this._tensor.dtype==tf.proto.DataType.DT_STRING?tf.Utility.decodeText(c):c),t.count++}else if(t.rawData)switch(this._tensor.dtype){case tf.proto.DataType.DT_FLOAT:o.push(t.rawData.getFloat32(t.index,!0)),t.index+=4,t.count++;break;case tf.proto.DataType.DT_INT32:o.push(t.rawData.getInt32(t.index,!0)),t.index+=4,t.count++;break;case tf.proto.DataType.DT_UINT32:o.push(t.rawData.getUint32(t.index,!0)),t.index+=4,t.count++;break;case tf.proto.DataType.DT_QINT8:o.push(t.rawData.getInt8(t.index,!0)),t.index+=1,t.count++;break;case tf.proto.DataType.DT_QUINT8:o.push(t.rawData.getUint8(t.index,!0)),t.index+=1,t.count++}}else for(let p=0;p<r;p++){if(t.count>t.limit)return o.push("..."),o;o.push(this._decode(t,e+1,s))}return t.shape.length==0?o[0]:o}static formatDataType(t){if(!tf.Tensor.dataType){tf.Tensor.dataType={};for(let e of Object.keys(tf.proto.DataType)){const s=tf.proto.DataType[e];e=e.startsWith("DT_")?e.substring(3):e,tf.Tensor.dataType[s]=e.toLowerCase()}tf.Tensor.dataType[tf.proto.DataType.DT_HALF]="float16",tf.Tensor.dataType[tf.proto.DataType.DT_FLOAT]="float32",tf.Tensor.dataType[tf.proto.DataType.DT_DOUBLE]="float64",tf.Tensor.dataType.DT_FLOAT="float32"}return tf.Tensor.dataType[t]||"?"}},tf.TensorType=class{constructor(t,e){this._dtype=t,this._shape=new tf.TensorShape(e)}get dataType(){return this._dtype?tf.Tensor.formatDataType(this._dtype):"?"}get shape(){return this._shape}toString(){return this.dataType+this._shape.toString()}},tf.TensorShape=class{constructor(t){this._shape=t}get dimensions(){return this._shape&&this._shape.dim?this._shape.unknown_rank?null:this._shape.dim.length==0?[]:this._shape.dim.length!=1||this._shape.dim[0].size?this._shape.dim.map(t=>t.size&&t.size!=-1?t.size:"?"):[0]:null}toString(){return this._shape&&this._shape.dim?this._shape.unknown_rank?"[-]":this._shape.dim.length==0?"":this._shape.dim.length!=1||this._shape.dim[0].size?"["+this._shape.dim.map(t=>t.size&&t.size!=-1?t.size.toString():"?").join(",")+"]":"[0]":"?"}},tf.TensorBundle=class{static open(t,e,s,o){const r=e.toLowerCase().endsWith(".index")?2:1;if(t.length<=48)throw new tf.Error("Invalid index file size.");const p=new tf.TensorBundle.BinaryReader(t,o);p.seek(-8);const c=[87,251,128,139,36,117,71,219];if(!p.bytes(8).every((m,T)=>m===c[T]))throw new tf.Error("Invalid table signature.");p.seek(-48),p.varint64(),p.varint64();const i=p.varint64(),a=p.varint64();p.seek(i);const n=p.clone(a),l=p.byte();if(l!==0)throw new tf.Error("Unsupported block compression '"+l+"'.");n.seek(-4);const h=n.int32();n.seek(-4-4*h);const u=[];for(let m=0;m<h;m++)u.push(n.int32());const _=new TextDecoder,f=new Map;for(let m=0;m<h;m++){n.seek(u[m]),n.varint32();const T=n.varint32(),x=n.varint32();n.skip(T);const v=n.clone(x);p.seek(v.varint64());const b=p.clone(v.varint64());let D="";for(;!b.end();){const k=b.varint32(),M=b.varint32(),O=b.varint32();if(k===0&&M===0&&O===0)break;D=D.substring(0,k),D+=_.decode(b.bytes(M));const A=b.bytes(O);f.set(D,A)}}if(!f.has(""))throw new tf.Error("Bundle header not available.");if(r===1)return Promise.resolve(new tf.TensorBundle(r,f,[]));const d=f.get(""),y=protobuf.Reader.create(d),g=tf.proto.BundleHeaderProto.decode(y).num_shards,w=[];for(let m=0;m<g;m++){const T=("0000"+m).slice(-5),x=("0000"+g).slice(-5),v=e.split(".");v.pop();const b=v.join(".")+".data-"+T+"-of-"+x;w.push(s.request(b,null))}return Promise.all(w).then(m=>new tf.TensorBundle(r,f,m)).catch(m=>(o.exception(m,!1),new tf.TensorBundle(r,f,null)))}constructor(t,e,s){switch(this._format=t,this._tensors=[],t){case 1:{const o=e.get(""),r=protobuf.Reader.create(o),p=tf.proto.SavedTensorSlices.decode(r),c=new Map;for(const i of e)if(i[0]!==""&&i[0]!=="global_step"){const a=protobuf.Reader.create(i[1]),n=tf.proto.SavedTensorSlices.decode(a),l=n.data.name,h=n.data.data;if(c.has(l)){const u=c.get(l);u!==null&&(h[u.key]&&h[u.key].length>0?u.value=u.value.concat(h[u.key]):c.set(l,null))}else if(h.tensor_content&&h.tensor_content.length>0)c.set(l,{key:"tensor_content",value:h.tensor_content});else{const u=Object.keys(h).filter(_=>_.endsWith("_val")&&h[_]&&h[_].length>0);c.set(l,u.length==1?{key:u[0],value:h[u[0]]}:null)}}for(const i of p.meta.tensor)if(i.name!=="global_step"){const a=new tf.proto.TensorProto;a.dtype=i.type,a.tensor_shape=i.shape;const n=c.get(i.name);n&&(a[n.key]=n.value),this._tensors.push(new tf.Tensor(a,i.name,null))}break}case 2:e.forEach((o,r)=>{if(r!==""){const p=protobuf.Reader.create(o),c=tf.proto.BundleEntryProto.decode(p),i=new tf.proto.TensorProto;i.dtype=c.dtype,i.tensor_shape=c.shape;const a=c.offset instanceof long.Long?c.offset.toNumber():c.offset,n=c.size instanceof long.Long?c.size.toNumber():c.size;s&&(i.tensor_content=s[c.shard_id].slice(a,a+n)),this._tensors.push(new tf.Tensor(i,r,null))}})}}get format(){return this._format}get tensors(){return this._tensors}},tf.TensorBundle.BinaryReader=class{constructor(t){t&&(this._buffer=t,this._dataView=new DataView(t.buffer,t.byteOffset,t.byteLength),this._position=0,this._start=0,this._end=this._buffer.length)}seek(t){if(this._position=t>=0?this._start+t:this._end+t,this._position>this._end)throw new tf.Error("Expected "+(this._position-this._end)+" more bytes. The file might be corrupted. Unexpected end of file.")}skip(t){if(this._position+=t,this._position>this._end)throw new tf.Error("Expected "+(this._position-this._end)+" more bytes. The file might be corrupted. Unexpected end of file.")}end(){return this._position>=this._end}clone(t){const e=new tf.TensorBundle.BinaryReader;return e._buffer=this._buffer,e._dataView=this._dataView,e._start=this._position,e._position=this._position,this.skip(t),e._end=this._position,e}bytes(t){const e=this._position;return this.skip(t),this._buffer.subarray(e,this._position)}byte(){const t=this._position;return this.skip(1),this._dataView.getUint8(t)}int32(){const t=this._position;return this.skip(4),this._dataView.getInt32(t,!0)}varint32(){return this.varint64()}varint64(){let t=0;for(let e=0;e<=63;e+=7){const s=this.byte();if(!(128&s)){t|=s<<e;break}t|=(127&s)<<e}return t}},tf.GraphMetadata=class{constructor(t){this._metadata=t,this._map={},this._attributeCache={}}type(t){var e=this._metadata.type(t);return e||(e=this._map[t]),e}attribute(t,e){let s=this._attributeCache[t];if(!s){s={};const o=this.type(t);if(o&&o.attributes&&o.attributes.length>0)for(const r of o.attributes)s[r.name]=r;this._attributeCache[t]=s}return s[e]||null}getAttributeVisibleMap(t){const e=this.type(t);if(e){let s=e.__visisbleAttributeMap__;if(!s){if(s={},e.inputs)for(const o of e.inputs)o.typeAttr?s[o.typeAttr]=!0:o.typeListAttr&&(s[o.typeListAttr]=!0),o.numberAttr&&(s[o.numberAttr]=!0);if(e.outputs)for(const o of e.outputs)o.typeAttr?s[o.typeAttr]=!0:o.typeListAttr&&(s[o.typeListAttr]=!0),o.numberAttr&&(s[o.numberAttr]=!0);e.__visisbleAttributeMap__=s}return s}return{}}static _formatAttributeValue(t){if(t==null)return null;if(t&&long.Long.isLong(t)&&(t=t.toNumber()),Array.isArray(t))return t.map(e=>tf.GraphMetadata._formatAttributeValue(e));if(t===Object(t))switch(t.type){case"type":return tf.Tensor.formatDataType(t.value);case"shape":case"tensor":return t.value}return typeof t=="string"?'"'+t+'"':t.toString()}},tf.Metadata=class{static open(t){return tf.Metadata._metadata?Promise.resolve(tf.Metadata._metadata):t.request(null,"tf-metadata.json","utf-8").then(e=>(tf.Metadata._metadata=new tf.Metadata(e),tf.Metadata._metadata)).catch(()=>(tf.Metadata._metadata=new tf.Metadata(null),tf.Metadata._metadata))}constructor(t){if(this._map={},t&&t){const e=JSON.parse(t);if(e)for(const s of e)s.name&&s.schema&&(s.schema.name=s.name,this._map[s.name]=s.schema)}}type(t){return this._map[t]}},tf.Utility=class{static decodeText(t){return typeof t=="string"?t:t.length===0?"":(tf.Utility._utf8Decoder=tf.Utility._utf8Decoder||new TextDecoder("utf-8"),tf.Utility._utf8Decoder.decode(t))}},tf.Error=class extends Error{constructor(t){super(t),this.name="Error loading TensorFlow model."}},typeof module!="undefined"&&typeof module.exports=="object"&&(module.exports.ModelFactory=tf.ModelFactory);
