var keras=keras||{},base=base||require("./base"),long=long||{Long:require("long")};keras.ModelFactory=class{match(t){const e=t.identifier,s=e.split(".").pop().toLowerCase();if(s==="h5"||s==="hd5"||s==="hdf5"||s==="keras"||s==="model"||s=="pb"||s=="pth"){const n=t.buffer,i=[137,72,68,70,13,10,26,10];return n&&n.length>i.length&&i.every((h,c)=>h===n[c])}if(s=="json"&&!e.endsWith("-symbol.json")){const n=t.text;if(n.indexOf('"mxnet_version":',0)==-1)try{let i=keras.JsonParser.parse(n);if(i&&i.nodes&&i.arg_nodes&&i.heads)return!1;if(i&&i.modelTopology&&(i=i.modelTopology),i&&i.model_config&&(i=i.model_config),i&&i.class_name||i&&Array.isArray(i)&&i.every(h=>Array.isArray(h.weights)&&Array.isArray(h.paths)))return!0}catch(i){}}return!1}open(t,e){return e.require("./hdf5").then(s=>{let n="Keras",i="",h="",c=null,u=null;const g=t.identifier,_=new keras.Weights;try{switch(g.split(".").pop().toLowerCase()){case"keras":case"h5":case"hd5":case"hdf5":case"model":case"pb":case"pth":if(u=new s.File(t.buffer).rootGroup,u.attribute("model_config")||u.attribute("layer_names")){const l=u.attribute("model_config");l&&(c=keras.JsonParser.parse(l)),h=u.attribute("backend")||"";const a=u.attribute("keras_version")||"";n+=a?" v"+a:"";let r=u.group("model_weights");if(!r&&u.attribute("layer_names")&&(r=u),r){r=new keras.Group(r);for(const p of r.attribute("layer_names")){const o=r.group(p);if(o){const f=o.attribute("weight_names");if(f&&f.length>0)for(const m of f){const y=o.group(m);if(y&&y.value){const d=y.value,w=new keras.Tensor(m,d.type,d.shape,d.littleEndian,d.data,"");if(c)_.add(p,w);else{const b=m.split("/");b.pop();const v=b.length==0||b[0]!==p?[p].concat(b).join("/"):b.join("/");_.add(v,w)}}}}}}}else{const l=new Set(["nb_layers"]);if(Object.keys(u.attributes).filter(a=>!l.has(a)).length!==0||u.value!==null)throw new keras.Error("File format is not HDF5 Weights");if(n="HDF5 Weights",Object.keys(u.attributes).length===0&&u.value===null&&u.groups.length==1&&u.groups[0]&&Object.keys(u.groups[0].attributes).length===0&&u.groups[0].value===null&&(u=u.groups[0]),u.groups.every(a=>Object.keys(a.attributes).length===0&&a.groups.length==0&&a.value!==null))for(const a of u.groups){const r=a.value,p=new keras.Tensor(a.name,r.type,r.shape,r.littleEndian,r.type==="string"?r.value:r.data);_.add("",p)}else if(u.groups.every(a=>Object.keys(a.attributes).length===0&&a.value===null))for(const a of u.groups){const r=a.attributes.name||a.name;for(const p of a.groups){if(Object.keys(p.attributes).length!==0||p.groups.length!==0)throw new keras.Error("Group format is not HDF5 tensor variable.");const o=p.value;if(!o)throw new keras.Error("Variable value is not HDF5 tensor.");const f=r?[r,p.name].join("/"):r.name,m=new keras.Tensor(f,o.type,o.shape,o.littleEndian,o.type==="string"?o.value:o.data);_.add(r,m)}}else{if(!u.groups.every(a=>a.value===null&&a.groups.every(r=>Object.keys(r.attributes).length===0&&r.value!==null)))throw new keras.Error("Module group format is not HDF5 Weights");for(const a of u.groups){const r=a.attributes.name||a.name;for(const p of a.groups){if(Object.keys(p.attributes).length!==0||p.groups.length!==0)throw new keras.Error("Variable format is not HDF5 Weights");const o=p.value;if(!o)throw new keras.Error("Variable value is not HDF5 Weights");const f=r?[r,p.name].join("/"):r.name,m=new keras.Tensor(f,o.type,o.shape,o.littleEndian,o.type==="string"?o.value:o.data);_.add(r,m)}}}}break;case"json":{const l=keras.JsonParser.parse(t.text);if(l&&Array.isArray(l)&&l.every(a=>Array.isArray(a.weights)&&Array.isArray(a.paths))){n="TensorFlow.js Weights",u={};for(const a of l)for(const r of a.weights){const p=new keras.Tensor(r.name,r.dtype,r.shape,!1,null,a.paths.join(";")),o=r.name.split("/");o.pop();const f=o.join("/");_.add(f,p)}}else{if(l.keras_version){const a=l.keras_version;n+=a?" v"+a:""}if(l.backend&&(h=l.backend),c=l,c&&c.modelTopology){h=c.modelTopology.backend;const a=c.modelTopology.keras_version;n+=a?" v"+a:"",n="TensorFlow.js "+(c.format?c.format:n),i=c.convertedBy||c.generatedBy||"";for(const r of c.weightsManifest)for(const p of r.weights){const o=new keras.Tensor(p.name,p.dtype,p.shape,!1,null,r.paths.join(";"));_.add("",o)}c=c.modelTopology}c.model_config&&(c=c.model_config)}break}}}catch(l){const a=l&&l.message?l.message:l.toString();throw new keras.Error(a.replace(/\.$/,"")+" in '"+g+"'.")}if(!u&&!c)throw new keras.Error("'model_config' is not present.");if(!u&&!c.class_name)throw new keras.Error("'class_name' is not present.");return keras.Metadata.open(e).then(l=>{try{return new keras.Model(l,n,i,h,c,_)}catch(a){e.exception(a,!1);const r=a&&a.message?a.message:a.toString();throw new keras.Error(r.replace(/\.$/,"")+" in '"+g+"'.")}})})}},keras.Model=class{constructor(t,e,s,n,i,h){this._format=e,this._backend=n,this._producer=s,this._graphs=[new keras.Graph(t,i,h)]}get name(){return null}get description(){return null}get format(){return this._format}get producer(){return this._producer}get runtime(){return this._backend}get graphs(){return this._graphs}},keras.Graph=class{constructor(t,e,s){if(this._metadata=t,this._inputs=[],this._outputs=[],this._nodes=[],this._groups=!1,e)switch(this._name=e.name||(e.config&&e.config.name?e.config.name:""),e.class_name){case"AllCNN":case"Sequential":this._loadSequential(e.config,s,"",null,null);break;case"Functional":case"Model":this._loadModel(e.config,s,"",null,null);break;default:throw new keras.Error("'"+e.class_name+"' is not supported.")}else if(s){for(const n of s.keys())if(s.get("",n).length<=6){const i=new keras.Node(t,"Weights",{name:n},[],[],"",s);this._nodes.push(i)}}}get name(){return this._name}get groups(){return!!this._groups}get inputs(){return this._inputs}get outputs(){return this._outputs}get nodes(){return this._nodes}_loadModel(t,e,s,n,i){s&&(this._groups=!0);const h=new Map;if(t.layers){for(const _ of t.layers)_.name&&(h.has(_.name)||(h.set(_.name,_),_._inputs=[],_._outputs=[]));for(const _ of t.layers)if(_.inbound_nodes)for(const l of _.inbound_nodes)for(const a of l){let r=a[0];const p=h.get(r);if(p){const o=a[2];for(o!=0&&(r+=":"+o.toString());o>=p._outputs.length;)p._outputs.push("");p._outputs[o]=r}_._inputs.push(r)}}const c=t.input_layers;if(c)for(let _=0;_<c.length;_++){const l=c[_][0];let a=null;const r=h.get(l);if(r&&r.class_name=="InputLayer"&&(a=this._getInputType(r),h.delete(l)),n&&_<n.length){if(t.layers)for(const p of t.layers)p._inputs&&(p._inputs=p._inputs.map(o=>o===l?n[_]:o))}else this._inputs.push(new keras.Parameter(l,!0,[new keras.Argument(l,a,null)]))}const u=new Map,g=t.output_layers;if(g)for(let _=0;_<g.length;_++){const l=g[_];let a=l[0];const r=h.get(a);let p=!0;if(i&&_<i.length&&(u.set(a,i[_]),a=i[_],p=!1),r){const o=l[2];for(o!=0&&(a+=":"+o.toString());o>=r._outputs.length;)r._outputs.push("");r._outputs[o]=a}p&&this._outputs.push(new keras.Parameter(a,!0,[new keras.Argument(a,null,null)]))}if(t.layers)for(const _ of t.layers)h.has(_.name)&&this._loadNode(_,_._inputs,_._outputs,e,s,u)}_loadSequential(t,e,s,n,i){s&&(this._groups=!0);const h="input";let c=null,u=h,g=0;const _=t.layers?t.layers:t;for(const l of _){let a=g.toString(),r=[u];g==0&&(n&&n.length>0?r=[n[0]]:c=this._getInputType(l)),g++,l.config&&l.config.name&&(a=l.config.name),u=a;let p=[u];g==_.length&&i&&i.length>0&&(p=[i[0]],u=null),this._loadNode(l,r,p,e,s)}n||this._inputs.push(new keras.Parameter(h,!0,[new keras.Argument(h,c,null)])),u&&this._outputs.push(new keras.Parameter(u,!0,[new keras.Argument(u,null,null)]))}_loadNode(t,e,s,n,i,h){const c=t.class_name;switch(c){case"Sequential":{const u=t.name||(t.config?t.config.name:"");this._loadSequential(t.config,n,(i?i+"/":"")+u,e,s);break}case"Model":{const u=t.name||(t.config?t.config.name:"");this._loadModel(t.config,n,(i?i+"/":"")+u,e,s);break}default:{e=e.map(g=>h&&h.has(g)?h.get(g):g);const u=new keras.Node(this._metadata,c,t.config,e,s,i,n);this._nodes.push(u);break}}}_getInputType(t){if(t&&t.config){let e="?",s=[];const n=t.config;return n.dtype&&(e=n.dtype,delete n.dtype),n.batch_input_shape&&(s=n.batch_input_shape.map(i=>i==null?"?":i),delete n.batch_input_shape),new keras.TensorType(e,new keras.TensorShape(s))}return null}},keras.Parameter=class{constructor(t,e,s){this._name=t,this._visible=e,this._arguments=s}get name(){return this._name}get visible(){return this._visible}get arguments(){return this._arguments}},keras.Argument=class{constructor(t,e,s){if(typeof t!="string")throw new keras.Error("Invalid argument identifier '"+JSON.stringify(t)+"'.");this._name=t,this._type=e||null,this._initializer=s||null}get name(){return this._name}get type(){return this._initializer?this._initializer.type:this._type}get initializer(){return this._initializer}},keras.Node=class{constructor(t,e,s,n,i,h,c){this._group=h||"",this._metadata=t,this._type=e;const u=s&&s.name?s.name:"";this._name=(this._group?this._group+"/":"")+u,this._inputs=[],this._outputs=[],this._attributes=[];let g=[u];if((e=="Bidirectional"||e=="TimeDistributed")&&s&&s.layer){const o=s.layer;delete s.layer,this._inner=new keras.Node(this._metadata,o.class_name,o.config,[],[],null,null),e=="Bidirectional"&&o.config.name&&(g=[u+"/forward_"+o.config.name,u+"/backward_"+o.config.name],h||(h=u))}const _={};if(c)for(const o of g)for(const f of c.get(h,o))n.push(f.name),_[f.name]=f;if(s)for(const o of Object.keys(s)){const f=s[o];o!="name"&&f!=null&&this._attributes.push(new keras.Attribute(t.attribute(this.type,o),o,f))}const l=this._metadata.type(this.type),a=this.inner?this.inner.type:null,r=a?this._metadata.type(a):null;let p=0;for(;n.length>0;){let o=!1,f=null,m=!0;if(r&&p!=0)switch(e){case"Bidirectional":{let d=p;r&&r.inputs&&(d<r.inputs.length?f="forward_"+r.inputs[d].name:(d=d-r.inputs.length+1,d<r.inputs.length&&(f="backward_"+r.inputs[d].name))),m=!1;break}case"TimeDistributed":r&&r.inputs&&p<r.inputs.length&&(f=r.inputs[p].name)}else if(l&&l.inputs&&p<l.inputs.length){const d=l.inputs[p];if(f=d.name,e==="BatchNormalization"&&f==="gamma"&&s.scale===!1){p++;continue}m=d.visible!=0,l.inputs[p].option=="variadic"&&(o=!0)}const y=(o?n.splice(0,n.length):[n.shift()]).map(d=>new keras.Argument(d,null,_[d]));if(!f&&y.length==1&&y[0].initializer&&y[0].initializer.name)if(g.length===1&&g[0]==="")f=y[0].initializer.name;else{const d=y[0].initializer.name.split("/").pop().split(":").shift().split("_"),w=d.pop(),b=d.length>0?[d.pop(),w].join("_"):"";f=new Set(["recurrent_kernel","running_mean","running_std","moving_mean","moving_variance","depthwise_filter","pointwise_filter"]).has(b)?b:w}this._inputs.push(new keras.Parameter(f||p.toString(),m,y)),p++}this._outputs=i.map((o,f)=>{const m=l&&l.outputs&&f<l.outputs.length&&l.outputs[f]&&l.outputs[f].name?l.outputs[f].name:f.toString();return new keras.Parameter(m,!0,[new keras.Argument(o,null,null)])})}get type(){return this._type}get metadata(){return this._metadata.type(this._type)}get name(){return this._name}get group(){return this._group}get inputs(){return this._inputs}get outputs(){return this._outputs}get attributes(){return this._attributes}get inner(){return this._inner}},keras.Attribute=class{constructor(t,e,s){switch(this._name=e,this._value=s,typeof s=="object"&&s.class_name&&s.config&&(this._value=keras.Attribute._convert(s)),e){case"trainable":this._type="boolean",this._visible=!1;break;case"dtype":this._visible=!1;break;default:t&&(t.type&&(this._type=t.type),(Object.prototype.hasOwnProperty.call(t,"visible")&&!t.visible||Object.prototype.hasOwnProperty.call(t,"default")&&keras.Attribute._isEquivalent(t.default,s))&&(this._visible=!1))}}get name(){return this._name}get type(){return this._type}get value(){return this._value}get visible(){return this._visible!=0}static _convert(t){if(Array.isArray(t)||t!==Object(t))return t;const e={};t.class_name&&(e.__type__=t.class_name);for(const s of Object.keys(t.config))e[s]=keras.Attribute._convert(t.config[s]);return e}static _isEquivalent(t,e){if(t===e)return t!==0||1/t==1/e;if(t==null||e==null)return!1;if(t!=t)return e!=e;const s=typeof t;if(s!=="function"&&s!=="object"&&typeof e!="object")return!1;const n=toString.call(t);if(n!==toString.call(e))return!1;switch(n){case"[object RegExp]":case"[object String]":return""+t==""+e;case"[object Number]":return+t!=+t?+e!=+e:+t==0?1/+t==1/e:+t==+e;case"[object Date]":case"[object Boolean]":return+t==+e;case"[object Array]":{let c=t.length;if(c!==e.length)return!1;for(;c--;)if(!keras.Attribute._isEquivalent(t[c],e[c]))return!1;return!0}}const i=Object.keys(t);let h=i.length;if(Object.keys(e).length!=h)return!1;for(;h--;){const c=i[h];if(!Object.prototype.hasOwnProperty.call(e,c)||!keras.Attribute._isEquivalent(t[c],e[c]))return!1}return!0}},keras.Tensor=class{constructor(t,e,s,n,i,h){this._name=t,this._type=new keras.TensorType(e,new keras.TensorShape(s)),this._littleEndian=n,this._data=i,this._reference=h}get kind(){return"Weights"}get name(){return this._name}get type(){return this._type}get reference(){return this._reference}get state(){return this._context().state}get value(){const t=this._context();return t.state?null:(t.limit=Number.MAX_SAFE_INTEGER,this._decode(t,0))}toString(){const t=this._context();if(t.state)return"";t.limit=1e4;const e=this._decode(t,0);return keras.Tensor._stringify(e,"","    ")}_context(){const t={index:0,count:0,state:null};if(this._reference)return t.state="Tensor reference not implemented.",t;if(!this._data)return t.state="Tensor data is empty.",t;switch(this._type.dataType){case"boolean":case"float16":case"float32":case"float64":case"uint8":case"int64":t.dataType=this._type.dataType,t.data=new DataView(this._data.buffer,this._data.byteOffset,this._data.byteLength),t.littleEndian=this._littleEndian;break;case"string":t.dataType=this._type.dataType,t.data=this._data;break;default:t.state="Tensor data type is not supported."}return t.shape=this._type.shape.dimensions,t}_decode(t,e){const s=t.shape.length!==0?t.shape:[1],n=[],i=s[e],h=t.littleEndian;if(e==s.length-1)for(let c=0;c<i;c++){if(t.count>t.limit)return n.push(null),n;switch(t.dataType){case"float16":n.push(t.data.getFloat16(t.index,h)),t.index+=2;break;case"float32":n.push(t.data.getFloat32(t.index,h)),t.index+=4;break;case"float64":n.push(t.data.getFloat64(t.index,h)),t.index+=8;break;case"boolean":n.push(t.data.getInt8(t.index)!==0),t.index+=1;break;case"uint8":n.push(t.data.getUint8(t.index)),t.index+=1;break;case"int64":n.push(new long.Long(t.data.getUint32(t.index+(h?0:4),h),t.data.getUint32(t.index+ +(h?4:0),h),!1)),t.index+=8;break;case"string":n.push(t.data[t.index]),t.index++}t.count++}else for(let c=0;c<i;c++){if(t.count>t.limit)return n.push(null),n;n.push(this._decode(t,e+1))}return t.shape.length==0?n[0]:n}static _stringify(t,e,s){if(Array.isArray(t)){const n=[];n.push(e+"[");const i=t.map(h=>keras.Tensor._stringify(h,e+s,s));return i.length>0&&n.push(i.join(`,
`)),n.push(e+"]"),n.join(`
`)}return t===null?e+"...":typeof t=="string"?e+'"'+t+'"':t==1/0?e+"Infinity":t==-1/0?e+"-Infinity":isNaN(t)?e+"NaN":e+t.toString()}},keras.TensorType=class{constructor(t,e){this._dataType=t,this._shape=e}get dataType(){return this._dataType}get shape(){return this._shape}toString(){return this._dataType+this._shape.toString()}},keras.TensorShape=class{constructor(t){this._dimensions=t}get dimensions(){return this._dimensions}toString(){return this._dimensions?"["+this._dimensions.map(t=>t.toString()).join(",")+"]":""}},keras.Metadata=class{static open(t){return keras.Metadata._metadata?Promise.resolve(keras.Metadata._metadata):t.request(null,"keras-metadata.json","utf-8").then(e=>(keras.Metadata._metadata=new keras.Metadata(e),keras.Metadata._metadata)).catch(()=>(keras.Metadata._metadata=new keras.Metadata(null),keras.Metadata._metadatas))}constructor(t){if(this._map=new Map,this._attributeCache=new Map,t){const e=JSON.parse(t);if(e)for(const s of e)s.name&&s.schema&&(s.schema.name=s.name,this._map.set(s.name,s.schema))}}type(t){return this._map.get(t)}attribute(t,e){const s=t+":"+e;if(!this._attributeCache.has(s)){const n=this.type(t);if(n&&n.attributes&&n.attributes.length>0)for(const i of n.attributes)this._attributeCache.set(t+":"+i.name,i);this._attributeCache.has(s)||this._attributeCache.set(s,null)}return this._attributeCache.get(s)}},keras.Group=class{constructor(t){this._group=t}attribute(t){let e=this._group.attribute(t);if(!e&&this._group.attribute(t+"0")){let s=0;for(e=[];;){const n=this._group.attribute(t+s.toString());if(!n)break;e=e.concat(n),s++}}return e}group(t){const e=this._group.group(t);return e?new keras.Group(e):null}get value(){return this._group.value}},keras.JsonParser=class{static parse(t){if(t&&(t.indexOf("NaN")!==-1||t.indexOf("Infinity")!==-1))try{return JSON.parse(t)}catch(e){try{return new keras.JsonParser(t)._read()}catch(s){}}return JSON.parse(t)}constructor(t){this._text=t,this._position=0,this._ch=" ",this._escape={'"':'"',"\\":"\\","/":"/",b:"\b",f:"\f",n:`
`,r:"\r",t:"	"}}_read(){const t=this._value();return this._whitespace(),this._ch&&this._error("Syntax error"),t}_next(){return this._ch=this._text.charAt(this._position++)}_expect(t){for(let e=0;e<t.length;e++)t[e]!==this._ch&&this._error("Expected '"+t[e]+"' instead of '"+this._ch+"'"),this._ch=this._text.charAt(this._position++)}_whitespace(){for(;this._ch&&this._ch<=" ";)this._next()}_number(){let t="";if(this._ch==="-"&&(t="-",this._expect("-")),this._ch==="I")return this._expect("Infinity"),-1/0;for(;this._ch>="0"&&this._ch<="9";)t+=this._ch,this._next();if(this._ch===".")for(t+=".";this._next()&&this._ch>="0"&&this._ch<="9";)t+=this._ch;if(this._ch==="e"||this._ch==="E")for(t+=this._ch,this._next(),this._ch!=="-"&&this._ch!=="+"||(t+=this._ch,this._next());this._ch>="0"&&this._ch<="9";)t+=this._ch,this._next();return+t}_string(){let t,e,s,n="";if(this._ch==='"')for(;this._next();){if(this._ch==='"')return this._next(),n;if(this._ch==="\\")if(this._next(),this._ch==="u"){for(s=0,e=0;e<4&&(t=parseInt(this._next(),16),isFinite(t));e++)s=16*s+t;n+=String.fromCharCode(s)}else{if(!this._escape[this._ch])break;n+=this._escape[this._ch]}else n+=this._ch}this._error("Invalid string")}_literal(){switch(this._ch){case"t":return this._expect("true"),!0;case"f":return this._expect("false"),!1;case"n":return this._expect("null"),null;case"N":return this._expect("NaN"),NaN;case"I":return this._expect("Infinity"),1/0}this._error("Unexpected '"+this._ch+"'")}_array(){const t=[];if(this._ch==="["){if(this._expect("["),this._whitespace(),this._ch==="]")return this._expect("]"),t;for(;this._ch;){if(t.push(this._value()),this._whitespace(),this._ch==="]")return this._expect("]"),t;this._expect(","),this._whitespace()}}this._error("Invalid array")}_object(){let t;const e={};if(this._ch==="{"){if(this._expect("{"),this._whitespace(),this._ch==="}")return this._expect("}"),e;for(;this._ch;){if(t=this._string(),this._whitespace(),this._expect(":"),Object.hasOwnProperty.call(e,t)&&this._error('Duplicate key "'+t+'"'),e[t]=this._value(),this._whitespace(),this._ch==="}")return this._expect("}"),e;this._expect(","),this._whitespace()}}this._error("Invalid object")}_value(){switch(this._whitespace(),this._ch){case"{":return this._object();case"[":return this._array();case'"':return this._string();case"-":return this._number();default:return this._ch>="0"&&this._ch<="9"?this._number():this._literal()}}_error(t){throw new Error(t+" at "+this._position+".")}},keras.Weights=class{constructor(){this._map=new Map}add(t,e){this._map.has(t)||this._map.set(t,[]),this._map.get(t).push(e)}get(t,e){if(t){const s=this._map.get(t.split("/").shift());if(s){const n=s.filter(h=>h.name.startsWith(e+"/"));if(n.length>0)return n;const i=s.filter(h=>h.name.startsWith(t+"/"+e+"/"));if(i.length>0)return i}}else{const s=this._map.get(e);if(s&&s.length>0)return s;const n=this._map.get("");if(n&&n.length>0){const i=n.filter(h=>h.name.startsWith((t?t+"/":"")+e+"/"));if(i.length>0)return i}}return[]}keys(){return this._map.keys()}},keras.Error=class extends Error{constructor(t){super(t),this.name="Error loading Keras model."}},typeof module!="undefined"&&typeof module.exports=="object"&&(module.exports.ModelFactory=keras.ModelFactory);
